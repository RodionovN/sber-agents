# Отчет о выполнении задания

## Название проекта

**Персональный финансовый советник** — Telegram бот для учета доходов и расходов с интеграцией LLM и мультимодальных возможностей.

### Краткое описание

Telegram бот, который помогает пользователям вести учет финансовых транзакций. Бот автоматически извлекает информацию о доходах и расходах из текстовых сообщений, изображений чеков и голосовых сообщений, используя современные LLM и VLM модели. Поддерживает работу как с облачными (OpenRouter), так и с локальными (Ollama) моделями.

---

## Вариант задания

**Расширенный вариант** — реализована полная мультимодальность:
- ✅ Обработка текстовых сообщений
- ✅ Обработка изображений (чеки, скриншоты)
- ✅ Обработка голосовых сообщений (транскрибация + извлечение транзакций)

---

## Реализованные возможности

### Основной функционал

- [x] Извлечение транзакций из текстовых сообщений через LLM со structured output
- [x] Обработка изображений чеков и скриншотов через VLM (Vision Language Model)
- [x] Транскрибация голосовых сообщений через Speech-to-Text API
- [x] Извлечение транзакций из транскрибированного текста
- [x] Автоматическая категоризация транзакций (продукты, рестораны, такси, транспорт и др.)
- [x] Определение типа транзакции (доход/расход)
- [x] Определение частоты транзакции (повседневные, периодические, разовые)
- [x] Расчет баланса (доходы - расходы)
- [x] Формирование отчета о балансе (`/balance`)
- [x] Просмотр всех транзакций (`/transactions`)
- [x] Статистика по категориям
- [x] История диалога для контекста при обработке сообщений

### Технические возможности

- [x] Поддержка работы с OpenRouter (облачные модели)
- [x] Поддержка работы с Ollama (локальные модели)
- [x] Единый интерфейс для переключения между провайдерами
- [x] Structured output через JSON schema для валидации ответов LLM
- [x] Поддержка нескольких провайдеров транскрибации:
  - [x] Yandex SpeechKit API
  - [x] OpenAI Whisper API
  - [x] Локальный faster-whisper
  - [x] Серверный Whisper API (через HTTP)
- [x] Обработка ошибок с понятными сообщениями пользователю
- [x] Логирование всех операций
- [x] Хранение данных в памяти (простота и скорость)

---

## Технологический стек

### Основные технологии

- **Python 3.11+** — основной язык разработки
- **uv** — современный менеджер зависимостей и виртуальных окружений
- **aiogram 3.x** — асинхронный фреймворк для Telegram Bot API (polling)
- **openai** (1.54.0+) — клиент для работы с LLM через единый интерфейс (OpenRouter/Ollama)
- **pydantic** (2.0.0+) — валидация данных и structured output для LLM
- **python-dotenv** — работа с переменными окружения
- **requests** — HTTP запросы для транскрибации
- **Make** — автоматизация сборки и запуска

### Используемые модели

**Для обработки текста:**
- `qwen2.5:7b-instruct` (Ollama) — основная модель для текстовых сообщений
- `llama3.2:1b` (Ollama) — легкая альтернатива
- `openai/gpt-oss-20b:free` (OpenRouter) — опционально для облачного использования

**Для обработки изображений:**
- `qwen3-vl:8b-instruct` (Ollama) — мультимодальная модель для обработки чеков и скриншотов
- `meta-llama/llama-3.2-11b-vision-instruct` (OpenRouter) — опционально для облачного использования

**Для транскрибации:**
- **faster-whisper** (локально на сервере) — модель `base` для баланса скорости и качества
- Yandex SpeechKit API — облачный провайдер с отличной поддержкой русского языка
- OpenAI Whisper API — альтернативный облачный провайдер

---

## Инструменты AI-driven разработки

### IDE и инструменты разработки

- **Cursor** — AI-powered IDE с интеграцией LLM для автодополнения и рефакторинга
- **Git** — система контроля версий
- **Make** — автоматизация задач

### Используемые LLM модели в разработке

- **Composer (Cursor AI)** — основная модель для генерации кода и рефакторинга
- Использовалась для:
  - Генерации кода обработчиков
  - Создания структуры проекта
  - Рефакторинга и оптимизации
  - Написания документации
  - Отладки и исправления ошибок

---

## Скриншоты работы

### Скриншот 1: Обработка текстового сообщения
![Обработка текстового сообщения](screenshots/Финансовый%20советник%201.png)

### Скриншот 2: Отчет о балансе
![Отчет о балансе](screenshots/Финансовый%20советник%202.png)

---

## Облачный сервер

### Провайдер

**immers.cloud** — облачный провайдер для размещения серверов с GPU

### Характеристики сервера

- **IP адрес:** 195.209.214.199
- **ОС:** Ubuntu 24.04 (Linux 6.14.0-33-generic)
- **GPU:** NVIDIA Tesla V100 PCIe 32GB
- **Python:** 3.12.3

### Установленные сервисы и модели

**Ollama:**
- Версия: последняя (Linux amd64)
- Порт: 11434 (доступен извне)
- Установленные модели:
  - `qwen2.5:7b-instruct` (4.7 GB)
  - `qwen3-vl:8b-instruct` (6.1 GB)
  - `llama3.2:1b` (1.3 GB)

**Whisper API сервер:**
- Порт: 8080 (доступен извне)
- Технология: Flask + faster-whisper
- Модель: Whisper `base` (баланс скорости и качества)
- Статус: ✅ Работает

**Дополнительное ПО:**
- ffmpeg — для обработки аудиофайлов
- faster-whisper — библиотека для транскрибации
- Flask — веб-фреймворк для API сервера

---

## Основные вызовы и решения

### Вызов 1: Интеграция транскрибации голосовых сообщений

**Проблема:** Нужно было выбрать между облачными API и локальным решением для транскрибации.

**Решение:** Реализован гибридный подход с поддержкой нескольких провайдеров:
- Облачные API (Yandex SpeechKit, OpenAI Whisper) для простоты интеграции
- Локальный faster-whisper для конфиденциальности и экономии
- Серверный Whisper API для использования GPU на удаленном сервере

**Результат:** Гибкая система с возможностью переключения между провайдерами через конфигурацию.

---

### Вызов 2: Единый интерфейс для разных провайдеров LLM

**Проблема:** Нужно было обеспечить работу с разными провайдерами (OpenRouter и Ollama) через единый интерфейс.

**Решение:** Использован официальный `openai` клиент с возможностью изменения `base_url`:
- Единый код для всех провайдеров
- Переключение через переменные окружения
- Поддержка structured output для всех провайдеров

**Результат:** Простое переключение между облачными и локальными моделями без изменения кода.

---

### Вызов 3: Structured output для валидации ответов LLM

**Проблема:** LLM могут возвращать некорректные форматы данных, требуется валидация.

**Решение:** Использован `response_format` с JSON schema из Pydantic моделей:
- Автоматическая валидация через Pydantic
- Строгая схема (`strict: True`) для соответствия формату
- Обработка ошибок парсинга с детальным логированием

**Результат:** Надежная валидация данных транзакций с понятными сообщениями об ошибках.

---

### Вызов 4: Обработка изображений через VLM

**Проблема:** Нужно было обработать изображения чеков и извлечь структурированные данные.

**Решение:** Использована мультимодальная модель `qwen3-vl:8b-instruct`:
- Конвертация изображений в base64
- Передача через vision API с structured output
- Тот же механизм валидации, что и для текста

**Результат:** Успешное распознавание и извлечение транзакций из изображений чеков.

---

### Вызов 5: Настройка серверного Whisper API

**Проблема:** Локальная установка faster-whisper требовала GPU, которого нет на локальной машине.

**Решение:** Создан простой HTTP API сервер на удаленном сервере:
- Flask сервер для обработки запросов
- Использование GPU на сервере для ускорения
- Единый интерфейс через HTTP запросы

**Результат:** Работа транскрибации через серверный API аналогично обработке изображений.

---

## Что узнал нового

### 1. Structured Output через JSON Schema

Узнал о возможности использования `response_format` с JSON schema для строгой валидации ответов LLM. Это позволяет гарантировать корректный формат данных без дополнительного парсинга и обработки ошибок.

### 2. Единый интерфейс для разных провайдеров LLM

Понял, что официальный `openai` клиент можно использовать не только с OpenAI API, но и с любыми совместимыми провайдерами (OpenRouter, Ollama) через изменение `base_url`. Это значительно упрощает интеграцию.

### 3. Архитектура мультимодальных ботов

Изучил подходы к обработке разных типов контента (текст, изображения, аудио) в едином боте. Важно разделять логику обработки каждого типа, но использовать единые механизмы валидации и сохранения данных.

### 4. Оптимизация транскрибации

Познакомился с faster-whisper как оптимизированной версией Whisper. Важно правильно выбирать размер модели и тип вычислений (CPU/GPU) для баланса между скоростью и качеством.

### 5. Принципы KISS и YAGNI в практике

Применил принципы простоты разработки на практике:
- Монолитная архитектура вместо микросервисов
- Хранение в памяти вместо БД для простоты
- Прямолинейный код без излишних абстракций
- Реализация только необходимого функционала

Это позволило быстро создать рабочий прототип без переусложнения.

---

## Статистика проекта

- **Итераций выполнено:** 6
- **Файлов в проекте:** 6 Python файлов в `src/`
- **Моделей установлено:** 3 модели Ollama + Whisper
- **Провайдеров транскрибации:** 4 варианта
- **Время разработки:** ~1 день активной работы

---

## Заключение

Проект успешно реализован с полной поддержкой мультимодальности. Бот может обрабатывать текстовые сообщения, изображения чеков и голосовые сообщения, извлекая структурированные данные о транзакциях. Использование современных LLM и VLM моделей позволяет достичь высокой точности распознавания и извлечения данных.

Архитектура проекта следует принципам простоты (KISS, YAGNI), что позволило быстро создать рабочий прототип без излишнего усложнения. Поддержка как облачных, так и локальных моделей дает гибкость в выборе провайдера в зависимости от требований к конфиденциальности и стоимости.

