import logging
import os
import time
import threading
from pathlib import Path
from typing import Optional, Dict, Any
from langsmith import Client
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_huggingface import HuggingFaceEmbeddings
from datasets import Dataset
from ragas import evaluate

# –û—Ç–∫–ª—é—á–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Xet storage –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–µ–π
os.environ.setdefault('HF_HUB_DISABLE_XET', '1')
from ragas.metrics import (
    Faithfulness,
    ResponseRelevancy,
    AnswerCorrectness,
    AnswerSimilarity,
    ContextRecall,
    ContextPrecision,
)
from ragas.metrics.base import MetricWithLLM, MetricWithEmbeddings
from ragas.llms import LangchainLLMWrapper
from ragas.embeddings import LangchainEmbeddingsWrapper
from ragas.run_config import RunConfig
from config import config
import rag

logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
_ragas_metrics = None
_ragas_run_config = None

class RateLimitedLLM:
    """
    Wrapper –¥–ª—è LLM —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limit
    –ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å RAGAS
    """
    def __init__(self, llm, delay_seconds: float = 4.0):
        object.__setattr__(self, '_llm', llm)
        object.__setattr__(self, 'delay_seconds', delay_seconds)
        object.__setattr__(self, 'last_request_time', 0)
        object.__setattr__(self, '_lock', threading.Lock())
    
    def __setattr__(self, name, value):
        """–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º setattr –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤"""
        if name.startswith('_') or name in ('delay_seconds', 'last_request_time', '_lock'):
            object.__setattr__(self, name, value)
        else:
            setattr(self._llm, name, value)
    
    def _wait_for_rate_limit(self):
        """–ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è rate limit"""
        with self._lock:
            current_time = time.time()
            time_since_last_request = current_time - self.last_request_time
            if time_since_last_request < self.delay_seconds:
                sleep_time = self.delay_seconds - time_since_last_request
                logger.debug(f"Rate limiting: sleeping {sleep_time:.2f} seconds")
                time.sleep(sleep_time)
            self.last_request_time = time.time()
    
    def _generate(self, messages, stop=None, run_manager=None, **kwargs):
        self._wait_for_rate_limit()
        return self._llm._generate(messages, stop=stop, run_manager=run_manager, **kwargs)
    
    def invoke(self, input, config=None, **kwargs):
        """–ú–µ—Ç–æ–¥ invoke –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å LangChain"""
        self._wait_for_rate_limit()
        return self._llm.invoke(input, config=config, **kwargs)
    
    def _stream(self, messages, stop=None, run_manager=None, **kwargs):
        self._wait_for_rate_limit()
        return self._llm._stream(messages, stop=stop, run_manager=run_manager, **kwargs)
    
    def __getattr__(self, name):
        """–î–µ–ª–µ–≥–∏—Ä—É–µ–º –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã –∏ –º–µ—Ç–æ–¥—ã –∫ –æ–±–µ—Ä–Ω—É—Ç–æ–º—É LLM"""
        return getattr(self._llm, name)

def create_ragas_embeddings():
    """
    –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è RAGAS embeddings –ø–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: openai, huggingface
    """
    provider = config.RAGAS_EMBEDDING_PROVIDER.lower()
    
    if provider == "openai":
        logger.info(f"Creating RAGAS OpenAI embeddings: {config.RAGAS_EMBEDDING_MODEL}")
        embedding_kwargs = {"model": config.RAGAS_EMBEDDING_MODEL}
        # –î–æ–±–∞–≤–ª—è–µ–º base_url –∏ api_key –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ñ–∏–≥–µ
        if config.OPENAI_BASE_URL:
            embedding_kwargs["base_url"] = config.OPENAI_BASE_URL
        if config.OPENAI_API_KEY:
            embedding_kwargs["api_key"] = config.OPENAI_API_KEY
        return OpenAIEmbeddings(**embedding_kwargs)
    
    elif provider == "huggingface":
        model_path = config.RAGAS_HUGGINGFACE_EMBEDDING_MODEL
        logger.info(f"Creating RAGAS HuggingFace embeddings: {model_path} on {config.RAGAS_HUGGINGFACE_DEVICE}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø—É—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–º
        model_path_obj = Path(model_path)
        if model_path_obj.exists() and model_path_obj.is_dir():
            logger.info(f"Using local model path: {model_path}")
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –ø—É—Ç—å –∞–±—Å–æ–ª—é—Ç–Ω—ã–π
            model_path = str(model_path_obj.resolve())
        else:
            logger.info(f"Using HuggingFace Hub model: {model_path}")
        
        return HuggingFaceEmbeddings(
            model_name=model_path,
            model_kwargs={'device': config.RAGAS_HUGGINGFACE_DEVICE},
            encode_kwargs={'normalize_embeddings': True}
        )
    
    else:
        raise ValueError(f"Unknown RAGAS embedding provider: {provider}. Use 'openai' or 'huggingface'")

def init_ragas_metrics():
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAGAS –º–µ—Ç—Ä–∏–∫ (–æ–¥–∏–Ω —Ä–∞–∑)
    
    –ü–æ –æ–±—Ä–∞–∑—Ü—É —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞ (—Ä–∞–∑–¥–µ–ª 5.1)
    """
    global _ragas_metrics, _ragas_run_config
    
    if _ragas_metrics is not None:
        return _ragas_metrics, _ragas_run_config
    
    logger.info("Initializing RAGAS metrics...")
    
    # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ rate limit –¥–ª—è –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π OpenRouter
    rate_limit_delay = None
    if config.OPENAI_BASE_URL and "openrouter" in config.OPENAI_BASE_URL.lower():
        if "free" in (config.RAGAS_LLM_MODEL or "").lower():
            # –õ–∏–º–∏—Ç: 16 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É = ~3.75 —Å–µ–∫—É–Ω–¥—ã –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º 4 —Å–µ–∫—É–Ω–¥—ã –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            rate_limit_delay = 4.0
            logger.warning(
                f"‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –º–æ–¥–µ–ª—å OpenRouter —Å –ª–∏–º–∏—Ç–æ–º 16 –∑–∞–ø—Ä–æ—Å–æ–≤/–º–∏–Ω—É—Ç—É. "
                f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞–¥–µ—Ä–∂–∫–∞ {rate_limit_delay} —Å–µ–∫ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏. "
                f"–û—Ü–µ–Ω–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏."
            )
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM –∏ embeddings –¥–ª—è RAGAS (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–π –æ—Ü–µ–Ω–∫–∏)
    # –°–æ–∑–¥–∞–µ–º LLM —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ (base_url –∏ api_key –¥–ª—è OpenRouter –∏ –¥—Ä—É–≥–∏—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤)
    llm_kwargs = {
        "model": config.RAGAS_LLM_MODEL,
        "temperature": 0,
        "max_tokens": 4000  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ OpenRouter
    }
    if config.OPENAI_BASE_URL:
        llm_kwargs["base_url"] = config.OPENAI_BASE_URL
    if config.OPENAI_API_KEY:
        llm_kwargs["api_key"] = config.OPENAI_API_KEY
    
    base_llm = ChatOpenAI(**llm_kwargs)
    
    # –û–±–µ—Ä—Ç—ã–≤–∞–µ–º LLM –≤ rate limiter –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if rate_limit_delay:
        langchain_llm = RateLimitedLLM(base_llm, delay_seconds=rate_limit_delay)
        logger.info(f"‚úì Rate limiting enabled: {rate_limit_delay}s delay between requests")
    else:
        langchain_llm = base_llm
    
    langchain_embeddings = create_ragas_embeddings()
    
    # –°–æ–∑–¥–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics = [
        Faithfulness(),
        ResponseRelevancy(strictness=1),
        AnswerCorrectness(),
        AnswerSimilarity(),
        ContextRecall(),
        ContextPrecision(),
    ]
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
    ragas_llm = LangchainLLMWrapper(langchain_llm)
    ragas_embeddings = LangchainEmbeddingsWrapper(langchain_embeddings)
    
    for metric in metrics:
        if isinstance(metric, MetricWithLLM):
            metric.llm = ragas_llm
        if isinstance(metric, MetricWithEmbeddings):
            metric.embeddings = ragas_embeddings
        run_config = RunConfig()
        metric.init(run_config)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    # –£–º–µ–Ω—å—à–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limit –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö OpenRouter
    # –õ–∏–º–∏—Ç: 16 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É –¥–ª—è free –º–æ–¥–µ–ª–µ–π
    run_config = RunConfig(
        max_workers=1,  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 4 –¥–æ 1 –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limit
        max_wait=300,   # –£–≤–µ–ª–∏—á–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è
        max_retries=5   # –ë–æ–ª—å—à–µ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ rate limit
    )
    
    _ragas_metrics = metrics
    _ragas_run_config = run_config
    
    logger.info(f"‚úì RAGAS metrics initialized: {', '.join([m.name for m in metrics])}")
    logger.info(f"‚úì RAGAS LLM: {config.RAGAS_LLM_MODEL}")
    logger.info(f"‚úì RAGAS Embedding Provider: {config.RAGAS_EMBEDDING_PROVIDER}")
    if config.RAGAS_EMBEDDING_PROVIDER == "openai":
        logger.info(f"‚úì RAGAS Embedding Model: {config.RAGAS_EMBEDDING_MODEL}")
    else:
        logger.info(f"‚úì RAGAS Embedding Model: {config.RAGAS_HUGGINGFACE_EMBEDDING_MODEL} on {config.RAGAS_HUGGINGFACE_DEVICE}")
    
    return _ragas_metrics, _ragas_run_config

def check_dataset_exists(dataset_name: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ LangSmith
    
    Args:
        dataset_name: –∏–º—è –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Returns:
        True –µ—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    """
    if not config.LANGSMITH_API_KEY:
        logger.error("LANGSMITH_API_KEY not set")
        return False
    
    try:
        client = Client()
        datasets = list(client.list_datasets(dataset_name=dataset_name))
        return len(datasets) > 0
    except Exception as e:
        logger.error(f"Error checking dataset: {e}")
        return False

def evaluate_dataset(dataset_name: Optional[str] = None) -> Dict[str, Any]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è evaluation RAG —Å–∏—Å—Ç–µ–º—ã
    
    –ü–æ –æ–±—Ä–∞–∑—Ü—É —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞ (—Ä–∞–∑–¥–µ–ª 5.2):
    1. –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –≤ LangSmith —Å blocking=False –∏ —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
    2. RAGAS batch evaluation
    3. –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç—Ä–∏–∫ –∫–∞–∫ feedback –≤ LangSmith
    
    Args:
        dataset_name: –∏–º—è –¥–∞—Ç–∞—Å–µ—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
    
    Returns:
        dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ evaluation
    """
    if not config.LANGSMITH_API_KEY:
        raise ValueError("LANGSMITH_API_KEY not set. Cannot run evaluation.")
    
    if dataset_name is None:
        dataset_name = config.LANGSMITH_DATASET
    
    logger.info(f"Starting evaluation for dataset: {dataset_name}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
    if not check_dataset_exists(dataset_name):
        raise ValueError(f"Dataset '{dataset_name}' not found in LangSmith")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
    ragas_metrics, ragas_run_config = init_ragas_metrics()
    
    client = Client()
    
    # ========== –®–∞–≥ 1: –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –∏ —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö ==========
    logger.info("\n[1/3] Running experiment and collecting data...")
    
    # –°–æ–∑–¥–∞–µ–º target —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –Ω–∞—à–µ–≥–æ RAG
    def target(inputs: dict) -> dict:
        """Target —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è evaluation"""
        question = inputs["question"]
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é RAG —Ü–µ–ø–æ—á–∫—É
        # –ü–µ—Ä–µ–¥–∞–µ–º —Ç–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å (–±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è evaluation)
        from langchain_core.messages import HumanMessage
        result = rag.get_rag_chain().invoke({"messages": [HumanMessage(content=question)]})
        
        return {
            "answer": result["answer"],
            "documents": result["documents"]
        }
    
    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è evaluate
    questions = []
    answers = []
    contexts_list = []
    ground_truths = []
    run_ids = []
    
    # evaluate() —Å blocking=False –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ç–µ—Ä–∞—Ç–æ—Ä
    for result in client.evaluate(
        target,
        data=dataset_name,
        evaluators=[],
        experiment_prefix="rag-evaluation",
        metadata={
            "approach": "RAGAS batch evaluation + LangSmith feedback",
            "model": config.MODEL,
            "embedding_model": config.EMBEDDING_MODEL,
        },
        blocking=False,
    ):
        run = result["run"]
        example = result["example"]
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        question = run.inputs.get("question", "")
        answer = run.outputs.get("answer", "")
        documents = run.outputs.get("documents", [])
        contexts = [doc.page_content if hasattr(doc, 'page_content') else str(doc) for doc in documents]
        ground_truth = example.outputs.get("answer", "") if example else ""
        
        questions.append(question)
        answers.append(answer)
        contexts_list.append(contexts)
        ground_truths.append(ground_truth)
        run_ids.append(str(run.id))
    
    logger.info(f"Experiment completed, collected {len(questions)} examples")
    
    # ========== –®–∞–≥ 2: RAGAS evaluation ==========
    logger.info("\n[2/3] Running RAGAS evaluation...")
    
    # –°–æ–∑–¥–∞–µ–º Dataset –¥–ª—è RAGAS
    ragas_dataset = Dataset.from_dict({
        "question": questions,
        "answer": answers,
        "contexts": contexts_list,
        "ground_truth": ground_truths
    })
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º evaluation
    ragas_result = evaluate(
        ragas_dataset,
        metrics=ragas_metrics,
        run_config=ragas_run_config,
    )
    
    ragas_df = ragas_result.to_pandas()
    
    logger.info("RAGAS evaluation completed")
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
    metrics_summary = {}
    for metric in ragas_metrics:
        if metric.name in ragas_df.columns:
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º nan –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ —Å—Ä–µ–¥–Ω–µ–≥–æ
            valid_scores = ragas_df[metric.name].dropna()
            if len(valid_scores) > 0:
                avg_score = valid_scores.mean()
                metrics_summary[metric.name] = avg_score
                logger.info(f"  {metric.name}: {avg_score:.3f} (valid: {len(valid_scores)}/{len(ragas_df)})")
            else:
                metrics_summary[metric.name] = float('nan')
                logger.warning(f"  {metric.name}: nan (no valid scores - –≤–æ–∑–º–æ–∂–Ω–æ rate limit –∏–ª–∏ –æ—à–∏–±–∫–∏ API)")
    
    # ========== –®–∞–≥ 3: –ó–∞–≥—Ä—É–∑–∫–∞ feedback –≤ LangSmith ==========
    logger.info("\n[3/3] Uploading feedback to LangSmith...")
    
    for idx, run_id in enumerate(run_ids):
        row = ragas_df.iloc[idx]
        
        for metric in ragas_metrics:
            if metric.name in row:
                score = row[metric.name]
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º nan –∑–Ω–∞—á–µ–Ω–∏—è
                if isinstance(score, float) and (score != score):  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ nan
                    logger.warning(f"Skipping nan score for {metric.name} in run {run_id}")
                    continue
                try:
                    client.create_feedback(
                        run_id=run_id,
                        key=metric.name,
                        score=float(score),
                        comment=f"RAGAS metric: {metric.name}"
                    )
                except Exception as e:
                    logger.error(f"Error creating feedback for {metric.name}: {e}")
    
    logger.info(f"Feedback uploaded ({len(run_ids)} runs)")
    
    return {
        "dataset_name": dataset_name,
        "num_examples": len(questions),
        "metrics": metrics_summary,
        "ragas_result": ragas_result,
        "run_ids": run_ids
    }

def main():
    """Main CLI function for evaluation"""
    import argparse
    
    parser = argparse.ArgumentParser(description="RAG evaluation using RAGAS metrics")
    parser.add_argument("--dataset", type=str, default=None, help="Dataset name (default: from config)")
    args = parser.parse_args()
    
    try:
        result = evaluate_dataset(args.dataset)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("\n" + "=" * 70)
        print("EVALUATION RESULTS")
        print("=" * 70)
        print(f"Dataset: {result['dataset_name']}")
        print(f"Examples processed: {result['num_examples']}")
        print("\nRAGAS Metrics:")
        
        metric_descriptions = {
            "faithfulness": "–û–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å (–Ω–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π)",
            "answer_relevancy": "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞",
            "answer_correctness": "–ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞",
            "answer_similarity": "–ü–æ—Ö–æ–∂–µ—Å—Ç—å –Ω–∞ —ç—Ç–∞–ª–æ–Ω",
            "context_recall": "–ü–æ–ª–Ω–æ—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞",
            "context_precision": "–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞"
        }
        
        for metric_name, score in result["metrics"].items():
            desc = metric_descriptions.get(metric_name, metric_name)
            if isinstance(score, float) and not (score != score):  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ nan
                emoji = "üü¢" if score >= 0.8 else "üü°" if score >= 0.6 else "üî¥"
                print(f"{emoji} {desc}: {score:.3f}")
            else:
                print(f"üî¥ {desc}: nan (–æ—à–∏–±–∫–∏ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏)")
        
        print("\n" + "=" * 70)
        print("Results uploaded to LangSmith as feedback")
        print("=" * 70)
        
    except ValueError as e:
        logger.error(f"ValueError: {e}")
        print(f"\n‚ùå Error: {e}")
        return 1
    except Exception as e:
        logger.error(f"Unexpected error: {e}", exc_info=True)
        print(f"\n‚ùå Unexpected error: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(main())

